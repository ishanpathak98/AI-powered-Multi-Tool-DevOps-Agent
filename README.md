# ğŸ¤– DevOps AI Agent â€“ Ishan Pathak

An AI-powered multi-tool DevOps Agent that automates infrastructure monitoring, anomaly detection, root cause analysis, and auto-remediation â€” designed using AWS, Terraform, Prometheus, Python, and LLMs (OpenAI/Ollama).

---

## ğŸ“Œ Project Overview

This agent handles two core workflows:

### 1ï¸âƒ£ CPU Spike Detection & Analysis
- Continuously monitors CPU usage using Prometheus Node Exporter.
- Detects spikes (e.g., >80% for 2+ minutes).
- Retrieves logs during anomaly window.
- Analyzes logs using LLM (OpenAI or Ollama) to identify root causes (e.g., memory leaks, infinite loops).

### 2ï¸âƒ£ Auto Remediation & Notification
- If confident, restarts the affected container or service.
- Verifies system health post-remediation.
- Notifies via Slack/email with a detailed incident summary and actions taken.

---

## âš™ï¸ Tech Stack

| Layer | Tools Used |
|------|------------|
| ğŸ§± Infrastructure | AWS EC2 (Free Tier), Terraform |
| ğŸ” Monitoring | Prometheus, Node Exporter |
| ğŸ“œ Log Collection | File-based logs or Loki (optional) |
| ğŸ§  AI Analysis | OpenAI API or Ollama (local LLM) |
| ğŸ” Remediation | Docker, systemctl |
| ğŸ“© Notifications | Slack Webhook, SMTP (optional) |
| ğŸ§  Orchestration | LangChain or Custom Python Agent |
| ğŸ–¥ï¸ Frontend (Optional) | Streamlit |

---

## ğŸ“ Project Structure

DevOpsAgent-IshanPathak/
â”œâ”€â”€ terraform/ # Terraform IaC for AWS Infra
â”‚ â”œâ”€â”€ main.tf
â”‚ â”œâ”€â”€ variables.tf
â”‚ â”œâ”€â”€ outputs.tf
â”‚ â””â”€â”€ user_data.sh
â”œâ”€â”€ agents/ # Python agent modules
â”‚ â”œâ”€â”€ monitor.py # CPU Monitoring tool
â”‚ â”œâ”€â”€ analyzer.py # Log analysis using LLM
â”‚ â”œâ”€â”€ remediator.py # Auto-remediation logic
â”‚ â””â”€â”€ notifier.py # Slack/email notifications
â”œâ”€â”€ logs/ # Sample synthetic logs
â”œâ”€â”€ frontend/ # Optional Streamlit dashboard
â”œâ”€â”€ tests/ # Test scenarios and scripts
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_agent.py # Main orchestrator
â””â”€â”€ README.md



---

## ğŸ—ï¸ Deployment Phases

### Phase 1: Infrastructure Setup (Terraform)
- Deploy EC2 (Ubuntu 22.04 t2.micro) with Docker, Prometheus Node Exporter, Python.
- Set up security groups, IAM roles, and basic monitoring stack.

### Phase 2: Monitoring Agent
- Prometheus fetches CPU metrics from Node Exporter.
- Python script polls Prometheus API to detect CPU spikes.

### Phase 3: Log Analysis Agent
- Logs retrieved from `/var/log/syslog` or `docker logs`.
- Sent to OpenAI or Ollama with a custom prompt.
- Root cause returned and parsed.

### Phase 4: Auto Remediation Agent
- If LLM suggests a fix with high confidence:
  - Restart Docker container or service.
  - Recheck CPU to confirm fix.
- Logs the fix taken.

### Phase 5: Notification Agent
- Sends Slack/email with:
  - Spike details
  - Root cause analysis
  - Action taken

---

## âœ… Bonus Features

- Extend to monitor **memory**, **disk**, and **network** spikes.
- **CI/CD Integration** via GitHub Actions monitoring.
- **Incident Archive** in SQLite or ChromaDB.
- **Auto Post-Mortems** using GDocs/Notion API.
- **Predictive Analysis** using Prophet/ARIMA for CPU trends.

---

## ğŸ§ª Testing Scenarios

| Scenario | Validation |
|----------|------------|
| CPU Spike | Simulate via `while true; do :; done` |
| Log Analysis | Inject synthetic errors (e.g., OOM, infinite loop) |
| Auto Remediation | Kill container and validate restart |
| Notification | Confirm Slack/email alerts with summary |

---

## ğŸ“½ï¸ Demo Video (Coming Soon)

A video walkthrough showcasing:
- CPU spike detection
- Log analysis using LLM
- Auto-remediation
- Notification summary

â³ Duration: Under 15 mins

---

## ğŸ™Œ Acknowledgements

- Inspired by best practices in DevOps automation and AIOps
- Built using open-source tools: Prometheus, LangChain, Docker, OpenAI, Streamlit, etc.

---

## ğŸ“„ License

This project is open-source and licensed under the MIT License.

